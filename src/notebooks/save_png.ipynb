{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5a00a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea14a8f",
   "metadata": {},
   "source": [
    "Save as numpy the mucilage patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab57bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your cached .npz file\n",
    "cache_file = \"/home/ubuntu/mucilage_pipeline/mucilage-detection/saved_npy/test_cache.npz\"  # or val.npz / test.npz\n",
    "out_file = \"/home/ubuntu/mucilage_pipeline/mucilage-detection/saved_npy/test_positive.npz\"\n",
    "\n",
    "# Load the cached dataset\n",
    "data = np.load(cache_file)\n",
    "X, y = data[\"X\"], data[\"y\"]  # X.shape = (N,H,W,C), y.shape = (N,)\n",
    "\n",
    "# Select only patches with label 1 (mucilage)\n",
    "mask = y == 1\n",
    "X_pos = X[mask]\n",
    "y_pos = y[mask]  # will be all 1, optional\n",
    "\n",
    "print(f\"Selected {len(X_pos)} positive patches out of {len(y)} total.\")\n",
    "\n",
    "# Save to a new npz file\n",
    "np.savez_compressed(out_file, X=X_pos, y=y_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b6785",
   "metadata": {},
   "source": [
    "Convert and save as RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c46e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ubuntu/mucilage_pipeline/mucilage-detection/saved_npy/test_positive.npz\"\n",
    "arr = np.load(path)\n",
    "X = arr['X']  # (N, H, W, C)\n",
    "output_dir = \"/home/ubuntu/mucilage_pipeline/mucilage-detection/rgb_patches\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i, patch in enumerate(X):\n",
    "    rgb = patch[:, :, [3, 2, 1]]  # RGB bands\n",
    "    # Percentile normalization\n",
    "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
    "    rgb = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
    "    rgb = (rgb * 255).astype(np.uint8)\n",
    "    # Save each patch as PNG\n",
    "    filename = os.path.join(output_dir, f\"patch_{i:04d}.png\")\n",
    "    cv2.imwrite(filename, cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d57d9f4",
   "metadata": {},
   "source": [
    "Convert annotations from Roboflow to binary masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b1e31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "✅ Masks for train saved to /home/ubuntu/mucilage_pipeline/mucilage-detection/roboflow_dataset/masks_train\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "✅ Masks for valid saved to /home/ubuntu/mucilage_pipeline/mucilage-detection/roboflow_dataset/masks_valid\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "✅ Masks for test saved to /home/ubuntu/mucilage_pipeline/mucilage-detection/roboflow_dataset/masks_test\n"
     ]
    }
   ],
   "source": [
    "# Path to your dataset\n",
    "base_dir = \"/home/ubuntu/mucilage_pipeline/mucilage-detection/roboflow_dataset\"\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "for split in splits:\n",
    "    img_dir = os.path.join(base_dir, split)\n",
    "    ann_path = os.path.join(img_dir, \"_annotations.coco.json\")\n",
    "    mask_dir = os.path.join(base_dir, f\"masks_{split}\")\n",
    "    os.makedirs(mask_dir, exist_ok=True)\n",
    "\n",
    "    coco = COCO(ann_path)\n",
    "\n",
    "    for img_id in coco.getImgIds():\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        img_name = img_info[\"file_name\"]\n",
    "        h, w = img_info[\"height\"], img_info[\"width\"]\n",
    "\n",
    "        mask = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "        for ann in anns:\n",
    "            # Convert polygon or RLE to binary mask\n",
    "            m = coco.annToMask(ann)\n",
    "            mask = np.maximum(mask, m * 255)\n",
    "\n",
    "        cv2.imwrite(os.path.join(mask_dir, img_name), mask)\n",
    "\n",
    "    print(f\"✅ Masks for {split} saved to {mask_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ccd7ed",
   "metadata": {},
   "source": [
    "Reconstruct original order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "412ca0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(labels_file, test_size=0.3, val_size=0.5, seed=42):\n",
    "    df = pd.read_csv(labels_file)\n",
    "\n",
    "    # first split train vs test\n",
    "    df_train, df_tmp = train_test_split(\n",
    "        df, test_size=test_size, stratify=df[\"label\"], random_state=seed\n",
    "    )\n",
    "    # then split train vs val\n",
    "    df_test, df_val = train_test_split(\n",
    "        df_tmp, test_size=val_size, stratify=df_tmp[\"label\"], random_state=seed\n",
    "    )\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "df = \"/home/ubuntu/mucilage_pipeline/mucilage-detection/csv/patches_final.csv\"\n",
    "df_train, df_val, df_test = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6860803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing TRAIN ===\n",
      "Found 222 refined masks for train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [00:00<00:00, 4052.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved refined masks to /home/ubuntu/mucilage_pipeline/mucilage-detection/saved_npy/train_masks_refined.npz\n",
      "\n",
      "=== Processing VAL ===\n",
      "Found 222 refined masks for val.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 6921.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved refined masks to /home/ubuntu/mucilage_pipeline/mucilage-detection/saved_npy/val_masks_refined.npz\n",
      "\n",
      "=== Processing TEST ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222 refined masks for test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 3230.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved refined masks to /home/ubuntu/mucilage_pipeline/mucilage-detection/saved_npy/test_masks_refined.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/home/ubuntu/mucilage_pipeline/mucilage-detection\"\n",
    "splits = {\n",
    "    \"train\": df_train,\n",
    "    \"val\": df_val,\n",
    "    \"test\": df_test\n",
    "}\n",
    "\n",
    "for split, df in splits.items():\n",
    "    print(f\"\\n=== Processing {split.upper()} ===\")\n",
    "\n",
    "    # Load original npz cache\n",
    "    cache_file = os.path.join(base_dir, f\"saved_npy/{split}_cache.npz\")\n",
    "    data = np.load(cache_file)\n",
    "    X, y = data[\"X\"], data[\"y\"]\n",
    "\n",
    "    # Identify positive/negative indices\n",
    "    # Indices\n",
    "    pos_indices = np.where(y == 1)[0]\n",
    "    neg_indices = np.where(y == 0)[0]\n",
    "\n",
    "    # Initialize empty masks (same number of patches as X)\n",
    "    H, W = 256, 256\n",
    "    M = np.zeros((len(X), H, W), dtype=np.uint8)\n",
    "\n",
    "    # Refined masks directory (from Roboflow export)\n",
    "    mask_dir = os.path.join(base_dir, f\"roboflow_dataset/masks\")\n",
    "\n",
    "    # Build prefix-based lookup dictionary for Roboflow masks\n",
    "    mask_lookup = {}\n",
    "    for fname in os.listdir(mask_dir):\n",
    "        if fname.startswith(\"patch_\"):\n",
    "            prefix = fname.split(\"_png\")[0]  # e.g. \"patch_0000\"\n",
    "            mask_lookup[prefix] = os.path.join(mask_dir, fname)\n",
    "\n",
    "    print(f\"Found {len(mask_lookup)} refined masks for {split}.\")\n",
    "\n",
    "    # Fill masks for positive patches\n",
    "    for i, idx in enumerate(tqdm(pos_indices)):\n",
    "        prefix = f\"patch_{i:04d}\"  # matches your exported patch names\n",
    "        mask_path = mask_lookup.get(prefix, None)\n",
    "        if mask_path:\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is not None:\n",
    "                M[idx] = (mask > 127).astype(np.uint8)\n",
    "            else:\n",
    "                print(f\"⚠️ Could not read {mask_path}\")\n",
    "        else:\n",
    "            print(f\"⚠️ Missing mask for {prefix} ({split})\")\n",
    "\n",
    "    # Save mask array aligned with original X\n",
    "    out_path = os.path.join(base_dir, f\"saved_npy/{split}_masks_refined.npz\")\n",
    "    np.savez_compressed(out_path, M=M)\n",
    "    print(f\"✅ Saved refined masks to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c82fabe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eopf)",
   "language": "python",
   "name": "eopf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
