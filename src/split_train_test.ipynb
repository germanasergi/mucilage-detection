{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4f544ae",
   "metadata": {},
   "source": [
    "# Prepare dataset for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315672b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d639cd0",
   "metadata": {},
   "source": [
    "# 1. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b2c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing .zarr files\n",
    "DATA_DIR = \"/home/ubuntu/mucilage_pipeline/mucilage-detection/data/adr_test/target\"\n",
    "\n",
    "# Bands to use for analytics\n",
    "BANDS = [\"b02\", \"b03\", \"b04\", \"b8a\", \"b11\", \"b12\", 'amei', 'ndwi']  # Blue, Green, Red, NIR, NIR narrow, SWIR1, SWIR2\n",
    "\n",
    "# zarr files\n",
    "zarr_files = glob.glob(os.path.join(DATA_DIR, \"*.zarr\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f8b74",
   "metadata": {},
   "source": [
    "# 2. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a2941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_to_10m(ds, band, ref):\n",
    "    \"\"\"\n",
    "    Resample band to match the resolution & grid of reference band.\n",
    "    ds: opened .zarr datatree\n",
    "    band: name of band to resample (string)\n",
    "    ref: name of reference band (string)\n",
    "    \"\"\"\n",
    "    crs_code = \"EPSG:32632\"\n",
    "\n",
    "    # Define reference band\n",
    "    ref_band = ds[f\"measurements/reflectance/r10m/{ref}\"]  # reference (10m red)\n",
    "    ref_band = ref_band.rio.write_crs(crs_code, inplace=True)\n",
    "\n",
    "    # Band to convert\n",
    "    band_20m = ds[f\"measurements/reflectance/r20m/{band}\"]\n",
    "    band_10m = band_20m.rio.write_crs(crs_code, inplace=True)  # ensure CRS\n",
    "\n",
    "    return band_10m.rio.reproject_match(ref_band)\n",
    "\n",
    "def compute_amei(ds, eps=1e-6):\n",
    "    red   = ds[\"measurements/reflectance/r10m/b04\"].values.astype(np.float32)\n",
    "    green = ds[\"measurements/reflectance/r10m/b03\"].values.astype(np.float32)\n",
    "    nir   = resample_to_10m(ds, 'b8a', 'b04')\n",
    "    nir = nir.values.astype(np.float32)\n",
    "    swir  = resample_to_10m(ds, 'b11', 'b04')\n",
    "    swir = swir.values.astype(np.float32)  # \"B11\" or \"B12\"\n",
    "\n",
    "    # AMEI = (2*red + nir - 2*swir) / (green + 0.25*swir)\n",
    "    denom = green + 0.25 * swir\n",
    "    amei  = (2*red + nir - 2*swir) / (denom + eps)  # eps avoids divide-by-zero\n",
    "\n",
    "    return amei\n",
    "\n",
    "def compute_ndwi(ds, eps=1e-6):\n",
    "    green = ds[\"measurements/reflectance/r10m/b03\"].values.astype(np.float32)\n",
    "    nir   = resample_to_10m(ds, 'b8a', 'b04')\n",
    "    nir = nir.values.astype(np.float32)\n",
    "\n",
    "    # AMEI = (green - nir) / (green + nir)\n",
    "    ndwi  = (green - nir) / (green + nir + eps)  # eps avoids divide-by-zero\n",
    "\n",
    "    return ndwi\n",
    "\n",
    "\n",
    "def build_stack_10m(ds, bands):\n",
    "    \"\"\"\n",
    "    Create (H, W, C) stack from selected bands/indices.\n",
    "    Assumes ds has reflectance bands and you may also compute indices like AMEI/NDWI.\n",
    "    \"\"\"\n",
    "    stack = []\n",
    "    ref_10m = ds[\"measurements/reflectance/r10m/b04\"]  # reference (10m red)\n",
    "    \n",
    "    for b in bands:\n",
    "        if b in ds['measurements/reflectance/r10m']:   # reflectance at 10m\n",
    "            arr = ds['measurements/reflectance/r10m'][b].values.astype(np.float32)\n",
    "        elif b in ds['measurements/reflectance/r20m']: # reflectance at 20m\n",
    "            arr = resample_to_10m(ds, b, 'b04')\n",
    "            arr = arr.values.astype(np.float32)\n",
    "        elif b == \"amei\":\n",
    "            arr = compute_amei(ds)  # your function\n",
    "        elif b == \"ndwi\":\n",
    "            arr = compute_ndwi(ds)  # youâ€™d need to define\n",
    "        else:\n",
    "            raise ValueError(f\"Band {b} not found or not supported.\")\n",
    "        \n",
    "        stack.append(arr)\n",
    "    stack = np.stack(stack, axis=-1)  # (H, W, C)\n",
    "    return stack\n",
    "\n",
    "\n",
    "def extract_patches_3d(array, patch_size=256, stride=256):\n",
    "    \"\"\"\n",
    "    Extract patches from (H, W, C) array.\n",
    "    Returns a list of patches with shape (patch_size, patch_size, C).\n",
    "    \"\"\"\n",
    "    H, W, C = array.shape\n",
    "    patches = []\n",
    "\n",
    "    for i in range(0, H - patch_size + 1, stride):\n",
    "        for j in range(0, W - patch_size + 1, stride):\n",
    "            patch = array[i:i+patch_size, j:j+patch_size, :]\n",
    "            patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "\n",
    "def process_folder(zarr_files, bands, patch_size=256, stride=256):\n",
    "    \"\"\"\n",
    "    Loop through all zarr files in a folder and extract patches.\n",
    "    \"\"\"\n",
    "    all_patches = []\n",
    "\n",
    "    for zf in zarr_files:\n",
    "        print(f\"Processing {zf} ...\")\n",
    "        ds = xr.open_datatree(zf, engine=\"zarr\", mask_and_scale=False)\n",
    "\n",
    "        stack = build_stack_10m(ds, bands)\n",
    "        patches = extract_patches_3d(stack, patch_size, stride)\n",
    "        \n",
    "        all_patches.extend(patches)  # you might want to save to disk instead\n",
    "    \n",
    "    return all_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d1e431",
   "metadata": {},
   "source": [
    "# 3. Patchify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adca576",
   "metadata": {},
   "source": [
    "Prepare 256x256xbands patches from each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5731db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/ubuntu/mucilage_pipeline/mucilage-detection/data/adr_test/target/S2B_MSIL2A_20240728T095549_N0511_R122_T32TQQ_20240728T114034.zarr ...\n",
      "Processing /home/ubuntu/mucilage_pipeline/mucilage-detection/data/adr_test/target/S2A_MSIL2A_20240723T100031_N0511_R122_T32TQR_20240723T155949.zarr ...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "patches = process_folder(zarr_files[:2], BANDS)\n",
    "\n",
    "print(f\"Total patches: {len(patches)}\")\n",
    "print(f\"Patch shape: {patches[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a954f08",
   "metadata": {},
   "source": [
    "# 4. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952d859c",
   "metadata": {},
   "source": [
    "Split into train/test/validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eopf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
